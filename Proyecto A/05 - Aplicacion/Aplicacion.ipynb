{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paquetes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "import jellyfish\n",
    "from joblib import dump, load"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importar Dataset\n",
    "\n",
    "Luego de haber tuneado y evaluado los modelos con el Train set, los elegimos según su performance en el Test set. Elegido el mejor de los modelos con el set de Test, entrenamos dicho modelo elegido con TODOS los datos. Acá importamos el dataset completo."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Importar dataset completo"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrenar Modelo\n",
    "\n",
    "En esta parte entrenamos al modelo elegido y guardamos el objeto en un archivo **joblib**, para luego ser importado por el script de la aplicación y poder ser utilizado de manera directa en las predicciones."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Entrenamos el modelo con el dataset completo."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Exportamos el archivo con el modelo entrenado.\n",
    "dump(model, 'trained_model.joblib') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "rf = load('/home/jcc/JuanCruz_Ubuntu/Repositorios_Activos/Proyecto_CDD/Proyecto A/00 - Creación Dataset y Variables/trained_rf.joblib')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "rf.get_params()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prueba Aplicación\n",
    "\n",
    "Podemos importar el módulo creado para usar la aplicación en un set de URLs que querramos."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "urls = ['https://git-scm.com/docs/gitignore', \n",
    "        'https://scikit-learn.org/stable/modules/model_persistence.html',\n",
    "        'https://www.lanacion.com.ar/',\n",
    "        'https://articulo.mercadolibre.com.ar/MLA-737102690-sommier-king-la-cardeuse-native-400-200x200-_JM?variation=95000501490#reco_item_pos=2&reco_backend=promotions-sorted-by-score-mla-A&reco_backend_type=low_level&reco_client=seller-promotions&reco_id=574ab7bd-21ab-43a8-a868-69b5785b0fc9&deal_print_id=25c97840-04f2-11ec-85d9-336a60e0da68&c_id=carouseldynamic-home&c_element_order=undefined&c_campaign=OFERTAS-X-24-HORAS&c_uid=25c97840-04f2-11ec-85d9-336a60e0da68',\n",
    "        'https://www.clarin.com/']\n",
    "\n",
    "prueba = pd.DataFrame({'url':urls})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from Aplicacion import DetectarPhishing"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "detector = DetectarPhishing()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Instancia del detector fue creada\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "pd.get_dummies(prueba['suffix']=='').columns[0] == False"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'suffix'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'suffix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-820801141cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprueba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'suffix'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'suffix'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "metric_domains = [\n",
    "    'amazon', \n",
    "    'instagram', \n",
    "    'google', \n",
    "    'whatsapp',  \n",
    "    'twitter',\n",
    "    'facebook',\n",
    "    'yahoo', \n",
    "    'wikipedia',\n",
    "    'baidu',\n",
    "    'paypal', \n",
    "    'mail', \n",
    "    'sfexpress' ,\n",
    "    'onedrive',\n",
    "    'excel', \n",
    "    'square', \n",
    "    'mail', \n",
    "    'office365', \n",
    "    'irs', \n",
    "    'tencent', \n",
    "    'creditagrecole s.a.',\n",
    "    'microsoft',\n",
    "    'blogspot',\n",
    "    'onedrive',\n",
    "    'payment',\n",
    "    'hsbc',\n",
    "    'secure',\n",
    "    'help',\n",
    "    'banco',\n",
    "    'bank',\n",
    "    'support',\n",
    "    'rakuten',\n",
    "    'steam',\n",
    "    'olx'\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "        data_urls = prueba\n",
    "        # Descomposición del URL.\n",
    "\n",
    "        data_urls['scheme'] = data_urls['url'].apply(lambda x: urlparse(x).scheme)\n",
    "\n",
    "        data_urls['domain_complete'] = data_urls['url'].apply(lambda x: urlparse(x).netloc)\n",
    "        data_urls['domain_complete'] = data_urls['domain_complete'].str.replace('www.', '')\n",
    "        data_urls['domain_complete'] = data_urls['domain_complete'].str.replace('www', '')\n",
    "\n",
    "        data_urls['domain'] = data_urls['domain_complete'].apply(lambda x: tldextract.extract(x).domain)\n",
    "        data_urls['subdomain'] = data_urls['domain_complete'].apply(lambda x: tldextract.extract(x).subdomain)\n",
    "        data_urls['suffix'] = data_urls['domain_complete'].apply(lambda x: tldextract.extract(x).suffix)\n",
    "\n",
    "        data_urls['subdomain'] = data_urls['subdomain'] + '.'\n",
    "        data_urls['subdomain'] = data_urls['subdomain'].replace('.', '')\n",
    "\n",
    "        data_urls['domain_subdomain'] = data_urls['subdomain'] + data_urls['domain']\n",
    "\n",
    "        data_urls['path'] = data_urls['url'].apply(lambda x: urlparse(x).path)\n",
    "\n",
    "        # Creación de Variables.\n",
    "\n",
    "        # Variables del dominio\n",
    "        # Cuenta los puntos\n",
    "        data_urls['dom_n_puntos'] = data_urls['domain_subdomain'].str.count('\\\\.')\n",
    "        data_urls['dom_n_guion'] = data_urls['domain_subdomain'].str.count('\\\\-')\n",
    "        data_urls['dom_n_guionbajo'] = data_urls['domain_subdomain'].str.count('\\\\_')\n",
    "\n",
    "        # Cuenta el largo total del dominio + subdominio\n",
    "        data_urls['dom_len_tot'] = data_urls['domain_subdomain'].str.len()\n",
    "        # Cuenta el largo del dominio y subdominio por separado\n",
    "        data_urls['dom_len'] = data_urls['domain'].str.len()\n",
    "        data_urls['dom_len_sub'] = data_urls['subdomain'].str.len()\n",
    "        data_urls['url_len'] = data_urls['url'].str.len()\n",
    "        # Cuenta vocales\n",
    "        data_urls['dom_vocales'] = data_urls['domain_subdomain'].str.lower().str.count(r'[aeiou]')\n",
    "        # Cuenta consonantes\n",
    "        data_urls['dom_cons'] = data_urls['domain_subdomain'].str.lower().str.count(r'[a-z]') - data_urls['dom_vocales']\n",
    "        # Cuenta números\n",
    "        data_urls['dom_num'] = data_urls['domain_subdomain'].str.count('\\d')\n",
    "        # Cuenta cantidad de caracteres diferentes\n",
    "        data_urls['dom_car_dif'] = data_urls['domain_subdomain'].apply(set).apply(len)\n",
    "\n",
    "        # Dominio es IP\n",
    "        ip_dummies = pd.get_dummies(data_urls['suffix'] == '')\n",
    "        if ip_dummies.shape[1] == 2:\n",
    "            data_urls['dom_ip'] = pd.get_dummies(data_urls['suffix'] == '', drop_first=True)\n",
    "        elif ip_dummies.shape[1] == 1:\n",
    "            if ip_dummies.columns[0] == False:\n",
    "                data_urls['dom_ip'] = pd.get_dummies(data_urls['suffix'] == '').replace(1,0)\n",
    "            else:\n",
    "                data_urls['dom_ip'] = pd.get_dummies(data_urls['suffix'] == '')\n",
    "            \n",
    "        # Variable dummy Scheme\n",
    "        sch_dummies = pd.get_dummies(data_urls['scheme'], prefix='sch')\n",
    "        data_urls = pd.concat([data_urls, sch_dummies], axis = 1)\n",
    "\n",
    "        # Variables de Suffix\n",
    "        data_urls['suf_len'] = data_urls['suffix'].str.len()\n",
    "\n",
    "        # Creamos e imprimimos una lista con el top 5 de sufijos.\n",
    "        top_suf_list = ['com', 'net', 'org', 'ru', 'xyz']\n",
    "        data_urls['suffix2'] = data_urls['suffix']\n",
    "        # Asignamos categoría 'other' a todas las clases que no pertenezcan a top_suf_list.\n",
    "        data_urls.loc[data_urls['suffix2'].isin(top_suf_list).apply(np.bitwise_not), 'suffix2'] = 'other'\n",
    "        # Armamos las columnas dummy.\n",
    "        suf_dummies = pd.get_dummies(data_urls['suffix2'], prefix='suf')\n",
    "        data_urls = pd.concat([data_urls, suf_dummies], axis = 1)\n",
    "\n",
    "        for domain in metric_domains:\n",
    "            data_urls['metric_ds_'+domain] = data_urls['domain_subdomain'].apply(lambda x: jellyfish.jaro_winkler(x, domain))\n",
    "            data_urls['metric_d_'+domain] = data_urls['domain'].apply(lambda x: jellyfish.jaro_winkler(x, domain))\n",
    "            data_urls['metric_s_'+domain] = data_urls['subdomain'].apply(lambda x: jellyfish.jaro_winkler(x, domain))\n",
    "            data_urls['metric_p_'+domain] = data_urls['path'].apply(lambda x: jellyfish.jaro_winkler(x, domain))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "data_urls['dom_ip']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: dom_ip, dtype: uint8"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "detector.prepararInput(prueba)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "detector.data.iloc[:,9:30]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   dom_num  dom_car_dif  dom_ip  sch_https  suf_len  suf_com  suf_org  \\\n",
       "0        0            7       0          1        3        1        0   \n",
       "1        0           11       0          1        3        0        1   \n",
       "2        0            6       0          1        6        0        0   \n",
       "3        0           13       0          1        6        0        0   \n",
       "4        0            6       0          1        3        1        0   \n",
       "\n",
       "   suf_other  metric_ds_amazon  metric_d_amazon  ...  metric_p_amazon  \\\n",
       "0          0          0.000000         0.000000  ...         0.488889   \n",
       "1          0          0.000000         0.000000  ...         0.526316   \n",
       "2          1          0.638889         0.638889  ...         0.000000   \n",
       "3          1          0.436508         0.472222  ...         0.504659   \n",
       "4          0          0.555556         0.555556  ...         0.000000   \n",
       "\n",
       "   metric_ds_instagram  metric_d_instagram  metric_s_instagram  \\\n",
       "0             0.588624            0.588624            0.000000   \n",
       "1             0.590741            0.590741            0.000000   \n",
       "2             0.324074            0.324074            0.000000   \n",
       "3             0.484127            0.296296            0.314815   \n",
       "4             0.518519            0.518519            0.000000   \n",
       "\n",
       "   metric_p_instagram  metric_ds_google  metric_d_google  metric_s_google  \\\n",
       "0            0.400000          0.436508         0.436508         0.000000   \n",
       "1            0.495712          0.500000         0.500000         0.000000   \n",
       "2            0.000000          0.000000         0.000000         0.000000   \n",
       "3            0.547640          0.436508         0.472222         0.425926   \n",
       "4            0.000000          0.000000         0.000000         0.000000   \n",
       "\n",
       "   metric_p_google  metric_ds_whatsapp  \n",
       "0         0.322222            0.511905  \n",
       "1         0.423977            0.430556  \n",
       "2         0.000000            0.500000  \n",
       "3         0.410394            0.505952  \n",
       "4         0.000000            0.430556  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dom_num</th>\n",
       "      <th>dom_car_dif</th>\n",
       "      <th>dom_ip</th>\n",
       "      <th>sch_https</th>\n",
       "      <th>suf_len</th>\n",
       "      <th>suf_com</th>\n",
       "      <th>suf_org</th>\n",
       "      <th>suf_other</th>\n",
       "      <th>metric_ds_amazon</th>\n",
       "      <th>metric_d_amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>metric_p_amazon</th>\n",
       "      <th>metric_ds_instagram</th>\n",
       "      <th>metric_d_instagram</th>\n",
       "      <th>metric_s_instagram</th>\n",
       "      <th>metric_p_instagram</th>\n",
       "      <th>metric_ds_google</th>\n",
       "      <th>metric_d_google</th>\n",
       "      <th>metric_s_google</th>\n",
       "      <th>metric_p_google</th>\n",
       "      <th>metric_ds_whatsapp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.588624</td>\n",
       "      <td>0.588624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.436508</td>\n",
       "      <td>0.436508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.511905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.590741</td>\n",
       "      <td>0.590741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495712</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423977</td>\n",
       "      <td>0.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.324074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436508</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504659</td>\n",
       "      <td>0.484127</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.547640</td>\n",
       "      <td>0.436508</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.410394</td>\n",
       "      <td>0.505952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hay que corregir la generación de dummies, get_dummies genera con las que están presentes pero no considera las que no aparecen. Hay que hacerlas fijas armando funciones para cada una.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "detector.calcularProbabilidad(prueba)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 145 and input n_features is 141 ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3a18d5763d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcularProbabilidad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprueba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/JuanCruz_Ubuntu/Repositorios_Activos/Proyecto_CDD/Proyecto A/05 - Aplicacion/Aplicacion.py\u001b[0m in \u001b[0;36mcalcularProbabilidad\u001b[0;34m(self, data_urls, direccion)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportarModelo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdireccion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediccion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediccion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    397\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 145 and input n_features is 141 "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1035c9f89031aae6b77741c225f5058c1a7f3b64d31e40a953affed9b532ab28"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}