---
title: "NB - Tuneo Modelos"
output: html_document
---

https://topepo.github.io/caret/index.html
https://www.cienciadedatos.net/documentos/41_machine_learning_con_r_y_caret

# Paquetes

```{r}
rm(list=ls())
library(caret)
library(readr)
library(dplyr)
library(ggplot2)
library(ranger)

setwd(getwd())
```


```{r}
# Linux
data <- read_csv('Proyecto A/00 - Creación Dataset y Variables/Dataset_Modelos.csv')
```

```{r}
# Windows
setwd("~/GitHub/Proyecto_CDD")
getwd()
data <- read_csv("./Proyecto A/00 - Creación Dataset y Variables/Dataset_Modelos.csv")
```

Borramos las variables de caracteres.

```{r}
char_vars <- c(#"X1", 
               "...1",
               "url", 
               "scheme", 
               "domain_complete", 
               "domain", 
               "subdomain", 
               "suffix", 
               "domain_subdomain", 
               "path", 
               "suffix2")

df <- data %>%
  select(-char_vars)
```



```{r}
names(df)
```

Partimos el dataset en partición de Train y Test. El objeto *train_index* tendrá el índice de el Train set.

```{r}
set.seed(45)
train_index <- createDataPartition(y = df$phishing, times = 1, p = 0.80, list = FALSE)

train <- df[train_index,]
test <- df[-train_index,]

train <- train %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))
test <- test %>%
  mutate(phishing = factor(phishing, labels = c("NoPhish", "Phish")))
#test1 <- df[-train_index,]

#test_index <- createDataPartition(y = test1$phishing, times = 1, p = 0.5, list = FALSE)

#test <- test1[test_index,]
#validation <- test1[-test_index,]
```

```{r}
train$phishing
df$phishing[train_index]
```

Armamos los folds de Cross-Validation, usamos k = 5. El objeto *resample_method* tendrá toda la información de las particiones de Cross-Validation que realizamos.

```{r}
set.seed(53)
k = 5
CV_folds <- createFolds(train$phishing, k = k, list = TRUE)

resample_method <- trainControl(method = "cv",
                                number = k,
                                verboseIter = TRUE,
                                classProbs = TRUE,
                                returnData = TRUE,
                                summaryFunction = twoClassSummary,
                                returnResamp = "final",
                                savePredictions = "final",
                                #search = "random",
                                index = CV_folds)

```

En esta parte armamos el dataset con los valores de los hiperparámetros que vamos a probar. Importante: Las columnas tienen que llevar el nombre de los hiperparámetros de ese modelo en el método (paquete) empleado.

```{r}
ridge_grid <- expand.grid(mtry = c(5,seq(10,150,20)),
                          splitrule = "gini",
                          min.node.size = c(1,3, 5, 7))
                            

dim(ridge_grid)
head(ridge_grid)
```



Corriendo esta celda se realiza Cross-Validation probando todas las combinaciones de hiperparámetros que determinamos previamente y se entrena el modelo final con todos los datos del Train set y con el set de hiperparámetros óptimos.

```{r}
a<- Sys.time()

ridge <- train(as.factor(phishing)~., 
               data = train, 
               method = "ranger", 
               trControl = resample_method,
               verbose = TRUE,
               tuneGrid = ridge_grid,
               #preProcess = c("center", "scale"),
               #tuneLength = 25,
               num.trees=150,
               max.depth=90,
               metric = "ROC")
b<- Sys.time()
```
```{r}
b-a
```

Imprimimos los resultados obtenidos por Cross-Validation.

```{r}
ridge
```

```{r}
ridge$bestTune
```

```{r}
ridge$preProcess
```



```{r} 
plot(ridge$results, xvar = "min.node.size")
plot(df_results, xvar = "min.node.size")
```

```{r}
plot2<-rf_resultados %>%
  filter(num.trees == 150)
ggplot(plot2, aes(x=min.node.size, y = ROC,color=as.factor(mtry)))+
  geom_point()+
  geom_line()+
  #expand_limits(y = c(0,1))+
  
  theme_bw()
```


```{r}
dim(test)
```


Matriz de Confusión del modelo entrenado con el set de Test.

```{r}
confusionMatrix(data = as.factor(predict(ridge, test)),
                reference = as.factor(test$phishing),
                positive = "1",
                mode = "everything")
```

# Guardar Resultados

En esta parte guardamos los resultados de la optimización de hiperparámetros mediante Cross-Validation. La celda comentada sirve para crear el archivo csv por primera vez. Una vez creado dejarla comentada y correr solamente la última celda para incluir los nuevos resultados.

**REEMPLAZAR EL NOMBRE DEL MODELO**
```{r}
aux<-ridge$results
aux["num.tres"]=150
aux["max.depth"]=70
```

```{r}
getwd()
write_csv(aux, file ="Resultados_RF.csv",append=T)
```

```{r}
getwd()
rf_resultados <- read_csv("Resultados_RF.csv")

df_results <- rbind(aux, a)
write_csv(df_results, file = "Resultados_RF.csv")
```

```{r}

```


